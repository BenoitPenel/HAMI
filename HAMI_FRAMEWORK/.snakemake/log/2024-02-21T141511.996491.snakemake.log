Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 2
Rules claiming more threads will be scaled down.
Job stats:
job                          count
-------------------------  -------
Filter_METABARCODING_DATA        1
total                            1

Select jobs to execute...
Execute 1 jobs...

[Wed Feb 21 14:15:12 2024]
localrule Filter_METABARCODING_DATA:
    input: /home/penelben/Documents/THESE/1st_paper/HAMI_FRAMEWORK/DATA/test_data/METABARCODING/AgriB03BB_abundance_raw_data_METABARCODING.tsv, /home/penelben/Documents/THESE/1st_paper/HAMI_FRAMEWORK/DATA/test_data/METABARCODING/AgriB03BB_Metadata_METABARCODING.csv
    output: /home/penelben/Documents/THESE/1st_paper/HAMI_FRAMEWORK/DATA/test_data/METABARCODING/AgriB03BB_tax.filter3.csv, /home/penelben/Documents/THESE/1st_paper/HAMI_FRAMEWORK/DATA/test_data/METABARCODING/AgriB03BB_abundance.filter3.csv
    jobid: 0
    reason: Missing output files: /home/penelben/Documents/THESE/1st_paper/HAMI_FRAMEWORK/DATA/test_data/METABARCODING/AgriB03BB_tax.filter3.csv, /home/penelben/Documents/THESE/1st_paper/HAMI_FRAMEWORK/DATA/test_data/METABARCODING/AgriB03BB_abundance.filter3.csv
    resources: tmpdir=/tmp

[Wed Feb 21 14:15:16 2024]
Finished job 0.
1 of 1 steps (100%) done
Complete log: .snakemake/log/2024-02-21T141511.996491.snakemake.log
