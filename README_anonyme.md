# HAMI : "Human Assited Molecular Identification" Framework
**A bioninformatics pipeline for processing Frogs output data, in accordance with the HAMI framework**

- **Please cite:** [![doi](https://img.shields.io/static/v1?label=doi&message=DOI)](DOI)
<br />

**Towards large-scale monitoring of biodiversity: a Human-Assisted Molecular Identification (HAMI) framework using metabarcoding while accounting for abundances and systemic errors**
<br />
*AUTHORS* <br />
*Method in Ecology and Evolution, XXXXX, XXXXX 2024*<br />
<br />

## Prerequisites

The role of HAMI snakemake pipeline is to process the output of the FROGS pipeline as part of the HAMI framework. To run HAMI pipeline, abudance data and multi-affiliations data from FROGS are thus necessary. 
<br />
<br />
Note that for running HAMI pipeline in contexte of HAMI framework, it is also necessary that your samples can be discrimated based on their name. Please use alphabectic prefix  for it e.g : 
Metabarcoding samples = META0001 while Barcoding sample = BAR0001 and control samples = NC(P/I/E)00001.
<br />
<br />
Also, duplicate of metabarcoding samples and control samples are necessary. Discrimination between duplicate will be done using suffix : e.g META0001-A / META0001-B. 
Information allowing discrimination between samples will thus be implemented in the config file (see below).

## Description  

### Tree structure :

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>
<body>
    <ul>
        <li><strong>HAMI</strong>
            <ul>
                <li><strong>DATA</strong>  
                    <ul>
                        <li>test_data 
                            <ul>
                                <li>testCOI_abundance_raw.csv</li>
                                <li>testCOI_multi-affiliations.csv</li>
                            </ul>
                        </li>
                    </ul>
                </li>
                <li><strong>HAMI_PIPELINE</strong> 
                    <ul>
                        <li>config.yaml</li>  
                        <li>HAMI_environment.yaml</li>  
                        <li>HAMI_PIPELINE.smk</li>   
                    </ul>
                </li>
                <li><strong>SCRIPTS</strong> 
                    <ul>
                        <li>clean_frogs.R</li>  
                        <li>filter_frogs.R</li>  
                        <li>pseudogene_and_redudancy.py</li>  
                        <li>Separate_data.py</li>  
                        <li>BARCODE_MAKER.py</li> 
                        <li>BARCODE_pseudogene_filter.py</li> 
                    </ul>
                </li>
              <li>ReadME.md</li>
            </ul>
        </li>
    </ul>
</body>
</html>

5 directories, 12 files

### Description :                   

Snakemake is a workflow management system written in Python. It facilitates the creation and execution of complex data analysis pipelines, particularly in bioinformatics and computational biology. It is associated to a config.yaml file as well as a environment.yaml file. Please check snakemake Tutorial for futher explications: [Snakemake tutorials](https://snakemake.readthedocs.io/en/stable/tutorial/tutorial.html)

Here HAMI_PIPELINE.smk is a snakemake workflow associated to HAMI framework. It is associateds to a config file (config.yaml) and an environement file (HAMI_environment.yaml).
Please check these files to understand how it works.


The role of this snakemake pipeline is to process the sequencing data at the output of the FROGS pipeline as part of the HAMI framework.
To do this, there are five successive rules:

- All : It represents the final outputs that need to be generated by the workflow. It triggers the execution of the entire workflow.

- Clean_and_Chimeres : R process for removing chimeric sequences using dada2 packages (Callahan et al., 2016 - Nature Methods)

- Separate_BARCODING_METABARCODING_data : Python process to discriminate between metabarcoding and barcoding samples

- Filter_METABARCODING_DATA: R process to filter data and eliminate noise and contamination (3 filter steps)

- Pseudogene_Filter_and_reduce_redundancy : Python process to delete pseudogene sequence and reduce data redundancy associates to intraspecific diversty

Each rule call a specific R or Python script saved in SCRIPTS directory. Two additional scripts are available. They allow to deleted pseudogene data in barcoding data and to produce full length COI barcode according to the optional step of HAMI framework, which are no implemented in the HAMI pipeline.

  <br />

## Installation
### Requirements

Before installation, the following packages should be available on your system must be installed on your system:

* Python >=3.0
* Miniconda3. Please choose the installer corresponding to your OS: [Miniconda dowloads](https://docs.conda.io/en/latest/miniconda.html)
* GIT


Below are debian commands to rapidly install them:
```
sudo apt-get install git
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
chmod u+x Miniconda3-latest-Linux-x86_64.sh
./Miniconda3-latest-Linux-x86_64.sh
```
When installation ask if you want to run conda init, answer yes.
  <br />
After installation ends, reload bash
```
bash 
```

### Installation
First of all, create a directory that corresponds to your project directory.

Download HAMI:
``` bash
git clone --recursive https://github.com/AUTHOR_REPOSITORY/HAMI.git
cd HAMI
```
When the git clone is finished, you should find a tree structure similar to the one shown at the beginning of this file.
To ensure the functionality of the HAMIE pipeline, no changes should be made to the tree structure.
Simply import the data that you wish to process in relation to your project into the /HAMI/DATA/ directory.
As a reminder, this pipeline processes the output data from FROGS pipeline. 


## Setup your environment

A Snakemake environment file is a file that specifies the software dependencies required for running a Snakemake workflow. It typically contains a list of software packages along with their versions, which are necessary for executing the various steps or rules defined in the workflow. The environment file ensures reproducibility by providing a consistent software environment for running the workflow across different computing environments. Please used this environement file to create a conda environement adapted to run HAMI framework (HAMI_PIPELINE.smk).
<br />
<br />
Do it as follows: 
``` bash
conda env create -f HAMI_PIPELINE/HAMI_environment.yaml  --name HAMI_environment
``` 
<br />

## Activate your environment

Before running HAMI pipeline, the previously created environement need to be activate as follows:

``` bash
conda activate HAMI_environment
```
To deactivate your environment use the following line code : 

``` bash
conda deactivate 
```
Don't forget to reactivate your conda environment each time you re-use the pipeline. 

<br />

## Setup your config file

When the conda environment has been setup, it time to adapt the config file according to your need for your project.

A Snakemake configuration file (config.yaml) is a file written in Python that contains configuration settings for a Snakemake workflow. The configuration file allows users to customize various aspects of the workflow, such as file paths and other workflow-specific settings.

Here is the list of specific setting which are necessary for running HAMI pipeline:

- Name of projet
- Name of the DNA fragment 
- Number of treads used to run some internal process
- Path to your directory project, as well as data directory and script directory

- Target taxonomic group
- ADN length
- Reading frame of the DNA (Check it before running the pipeline)
- List of the codon stop associated to your type of DNA and organisms
- Arbitrary threshold to discriminated intra-interspecific genetic distance  (usually 97% for animals according to Hebert et al 2003 - Proceedings of the Royal Society of London)

- Samples prefix for metabarcoding samples, barcoding (if implemented), and negative control
- Number of digits following the prefix
- Samples suffix for discriminating duplicate


## Test and run your pipeline

To launch the pipeline from a terminal, go to the HAMI directory.

It is strongly recommended to test if your configuration is valid and matches the analyses you intended. To do so, launch a dry run of the pipeline using the command:

``` bash
snakemake --snakefile HAMI_PIPELINE/HAMI_PIPELINE.smk -np
```
If no error is throwed, you can lauch the pipeline :

``` bash
snakemake --snakefile HAMI_PIPELINE/HAMI_PIPELINE.smk --cores [#cores]
```

## Contact
*CORRESPONDING AUTHOR*
CONTACTS

## Licence
HAMI is availale under the Creative Commons Zero v1.0 Universal license
